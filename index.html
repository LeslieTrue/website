<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tianzhe Chu</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tianzhe Chu</name>
              </p>
              <p>Hi, I‚Äôm Tianzhe Chu(Ë§öÂ§©Âì≤). I‚Äôm a junior undergraduate student major in Computer Science at ShanghaiTech University
                and spent a wonderful year(22-23) in UC Berkeley. 
                 I‚Äôm a big fan of Chopin and Rachmaninoff. 
                 I'm from Suzhou(Soo Chow), China.
              </p>
              <p style="text-align:center">
                <a href="mailto: tianzhechu@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/resume_ctz.pdf">Resume</a> &nbsp/&nbsp
                <a href="data/courses.pdf">Classes</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=hYlbtl8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://github.com/LeslieTrue">Github</a> &nbsp/&nbsp
                <a href="https://boundarie.github.io/multi/#/">Music Review</a> &nbsp/&nbsp
                <a href="Coming!">Photos(Undergoing)</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/myself.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/myself.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am currently an undergraduate researcher in Berkeley Artificial Intelligence Research Lab(BAIR) advised by Prof. Yi Ma, working closely
                 with <a href="https://tianjiaoding.com/">Tianjiao Ding</a> from Prof. Ren√© Vidal's lab in JHU(UPenn) and <a href="https://tsb0601.github.io/petertongsb/">Peter Tong</a>. My 
                research interest lies in deep representation learning and 3D vision. More specifically, 
                I'm interested in unsupervised/self-supervised learning, subspace clustering, generative models(2D or 3D), 3D view synthesis(NeRFs). I also 
                strongly admire theory people and hope one day interpretable learning frameworks can be widely used.
              </p>
              <p>Feel free to reach out to talk about research, music, cooking, etc.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p><strong>May 2023:</strong> Gonna leave lovely Berkeley (as well as U.S.), finishing 7 tech courses and a few interesting research projects. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Publications & Preprints (* means equal contribution)</heading>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CPP2.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models</papertitle>
              </a>
              <br>
              <strong>Tianzhe Chu*</strong>, 
              <a href="https://tsb0601.github.io/petertongsb/">Shengbang Tong*</a>, 
              <a href="https://tianjiaoding.com/">Tianjiao Ding*</a>, 
              <a href="https://delay-xili.github.io/">Xili Dai</a>, 
              <a href="https://www.cis.jhu.edu/~haeffele/">Benjamin D. Haeffele</a>, 
              <a href="http://vision.jhu.edu/rvidal.html">Ren√© Vidal</a>, 
              <a href="http://people.eecs.berkeley.edu/~yima/">Yi Ma</a>
              <br>
              <em>Under Review</em>
              <br>
              <a href="projects/CPP.html">project page</a> / <a href="https://github.com/LeslieTrue/CPP">code</a> / arxiv
              <br>
              <p></p>
              <p>This paper proposes a novel image clustering pipeline that integrates pre-trained models and rate reduction, enhancing clustering accuracy and introducing an effective self-labeling algorithm for unlabeled datasets at scale.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CRATE.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle>White-Box Transformers via Sparse Rate Reduction</papertitle>
              </a>
              <br>
              <a href="https://yaodongyu.github.io/">Yaodong Yu</a>, 
              <a href="https://sdbuchanan.com/">Sam Buchanan</a>, 
              <a href="https://druvpai.github.io/">Druv Pai</a>, 
              <strong>Tianzhe Chu</strong>, 
              <a href="https://robinwu218.github.io/">Ziyang Wu</a>, 
              <a href="https://tsb0601.github.io/petertongsb/">Shengbang Tong</a>, 
              <a href="https://www.cis.jhu.edu/~haeffele/">Benjamin D. Haeffele</a>, 
              <a href="http://people.eecs.berkeley.edu/~yima/">Yi Ma</a>
              <br>
              <em>Under Review</em>
              <br>
              <a href="https://github.com/Ma-Lab-Berkeley/CRATE">code</a> / <a href="https://arxiv.org/abs/2306.01129">arxiv</a>
              <br>
              <p></p>
              <p>We develop white-box transformer-like deep network architectures which are mathematically interpretable and achieve performance very close to ViT.</p>
            </td>
          </tr>
          
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/t10ssl.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle> Pushing the Limit of Training Efficiency in Self-Supervised Learning </papertitle>
              </a>
              <br>
              <strong>Shengbang Tong*</strong>, <a>Yubei Chen*</a>, <a>Yi Ma</a>, <a>Yann Lecun</a>
              <br>
              <em>Under Review</em>
              <br>
              <p></p>
              <p>Inspired by the newly proposed principle, our work proposes a minimalist method for self-supervised learning that tremendously reduces the epochs which SSL methods take to converge.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/uCTRL.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2210.16782" id="uctrl">
                <papertitle>Unsupervised Learning of Structured Representation via Closed-Loop Transcription</papertitle>
              </a>
              <br>
              <strong>Shengbang Tong*</strong>, <a href = "https://delay-xili.github.io/">Xili Dai*</a>, <a>Yubei Chen</a>, <a>Mingyang Li</a>, <a>Zengyi Li</a>,  <a>Brent Yi</a>, <a>Yann Lecun</a>, <a>Yi Ma</a>
              <br>
              <em>Under Review</em>
              <br>
              <p></p>
              <p>This paper proposes a new unsupervised method to learn a structured representation that may serve both discriminative and generative purpose</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CSC_CTRL.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle> Closed-Loop Transcription Via Convolutional Sparse Coding</papertitle>
              </a>
              <br>
              <a>Xili Dai*</a>, <a>Ke Chen*</a>, <strong>Shengbang Tong*</strong>, <a>Jingyuan Zhang*</a>, <a>Xingjian Gao</a>, <a>Mingyang Li</a>, <a>Druv Pai</a>, <a>Yuexiang Zhai</a>, <a>Xiaojun Yuan</a>, <a>Heung Yeung Shum</a>, <a>Lionel M.Ni</a>, <a>Yi Ma</a>
              <br>
              <em>Under Review</em>
              <br>
              <p></p>
              <p>This paper proposes a new unsupervised method to learn a represenation and cluster for real life dataset such as CIFAR-10, CIFAR100 and Tiny-ImageNet-200.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MCRSE.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2301.01805" id="umlc">
                <papertitle>Unsupervised Manifold Linearizing and Clustering</papertitle>
              </a>
              <br>
              <a>Tianjiao Ding</a>, <strong>Shengbang Tong</strong>, <a>Kwan Ho Ryan Chan</a>, <a href = "https://delay-xili.github.io/">Xili Dai</a>, <a>Yi Ma</a>,<a>Benjamin David Haeffele</a>
              <br>
              <em>Under Review</em>
              <br>
              <p></p>
              <p>This paper proposes a new unsupervised method to learn a represenation and cluster for real life dataset such as CIFAR-10, CIFAR100 and Tiny-ImageNet-200.</p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sdnet.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2210.12945" id="revisit">
                <papertitle>Revisiting Sparse Convolutional Model for Visual Recognition</papertitle>
              </a>
              <br>
              <a href = "https://delay-xili.github.io/">Xili Dai*</a>,  <a>Mingyang Li*</a>, <a>Pengyuan Zhai</a>,  <strong>Shengbang Tong</strong>, <a>Xingjian Gao</a>, <a>Shaolun Huang</a>, <a>Zhihui Zhu</a>, <a>Chong You</a>, <a>Yi Ma</a>
              <br>
              <em>Accepted by Nips 2022</em>
              <br>
              <p></p>
              <p>Our method uses differentiable optimization layers that are defined from convolutional sparse coding as drop-in replacements of standard convolutional layers in conventional deep neural networks. We show that such models have equally strong empirical performance on CIFAR-10, CIFAR-100 and ImageNet datasets when compared to conventional neural networks.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iLDR.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2202.05411" id="iLDR">
                <papertitle>Incremental Learning of Structured Memory via Closed-Loop Transcription</papertitle>
              </a>
              <br>
              <strong>Shengbang Tong</strong>, <a href = "https://delay-xili.github.io/">Xili Dai</a>, <a>Ziyang Wu</a>, <a>Mingyang Li</a>, <a>Brent Yi</a>, <a>Yi Ma</a>
              <br>
              <em>Accepted by ICLR 2023</em>
              <br>
              <p></p>
              <p>We propose a minimal computational model for learning a structured memory of multiple object classes in an incremental setting</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LDR.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2111.06636" id="LDR">
                <papertitle>Closed-Loop Data Transcription to an LDR via Minimaxing Rate Reduction</papertitle>
              </a>
              <br>
              <a href = "https://delay-xili.github.io/">Xili Dai*</a>, <strong>Shengbang Tong*</strong>, <a>Mingyang Li*</a>, <a>Ziyang Wu*</a>, <a>Kwan Ho Ryan Chan</a>, <a>Pengyuan Zhai</a>, <a>Yaodong Yu</a>, <a>Michael Psenka</a>, <a>Xiaojun Yuan</a>, <a>Heung Yeung Shum</a>, <a>Yi Ma</a>
              <br>
              <em>Accepted by Entropy Journal</em>
              <br>
              <p></p>
              <p>We propose a new computational framework for learning an explicit generative model for real-world dataset.</p>
            </td>
          </tr> -->



        <!-- </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Projects</heading>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/nerf.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/LeslieTrue/" id="revisit">
                <papertitle>(Undergoing, placeholder) Reimplementation of Instant NGP</papertitle>
              </a>
              <br>
              Paper by M√ºller et al. Reimplementation by <strong>Tianzhe Chu</strong>.
              <br>
              <em>Just for fun</em>
              <br>
              <p></p>
              <p>Instant-ngp via pytorch or Jax or both.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cg.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://leslietrue.github.io/cs184-project-webpage/" id="revisit">
                <papertitle>(Undergoing) Computer Graphics</papertitle>
              </a>
              <br>
              <strong>Tianzhe Chu</strong>
              <br>
              <em>CS 184 Computer Graphics Course Project</em>
              <br>
              <p></p>
              <p>It's a perfect walkthrough of fondamental knowledge in CG.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rt.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/LeslieTrue/cs285_Project" id="revisit">
                <papertitle>Reward Transformer</papertitle>
              </a>
              <br>
              <strong>Tianzhe Chu</strong>
              <br>
              <em>CS 285 Deep Reinforcement Learning Course Project</em>
              <br>
              <p></p>
              <p>This method proposes a new way to learn the reward distribution of an environment.</p>
            </td>
          </tr> -->
          <table class="sub-table" style="width: 200px;height: 100px;" align="center">
            <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=nEvxroNDI3_wu2TwxRHbnuaFfZev0Sw-nUM4vqHVdQU&cl=ffffff&w=a"></script>
          </table>
        </tbody>
        </table>



      </td>
    </tr>
  </table>
</body>

</html>
